{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set libraries to refresh\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering.kmeans import custom_kmeans, get_oversized_clusters, run_optuna_kmeans_study, kmeans_secondpass #, parallel_kmeans_secondpass\n",
    "from utils import plot_weights_vs_radii\n",
    "from clustering.kmeans_new import get_optimised_kmeans_clusters_doublepass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(\"..\")\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "INPUT_DATA_DIR = DATA_DIR / \"input\"\n",
    "OUTPUT_DATA_DIR = DATA_DIR / \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"rooftops\"\n",
    "# data_type = \"grids\"\n",
    "\n",
    "# runs\n",
    "n_jobs = 10\n",
    "firstpass_n_trials = 50\n",
    "secondpass_n_trials = 20\n",
    "\n",
    "if data_type == \"rooftops\":\n",
    "\n",
    "    gdf_for_cluster = gpd.read_parquet(INPUT_DATA_DIR / \"rooftops.parquet\")\n",
    "    gdf_for_cluster.loc[:, \"weight\"] = 1\n",
    "    # admin variables\n",
    "    id_col = \"rooftop_id\"\n",
    "    lat_col = \"Lat_centroid\"\n",
    "    lon_col = \"Lon_centroid\"\n",
    "    weight_col = \"weight\"\n",
    "    epsg = 26191  # morocco\n",
    "    # clustering variables\n",
    "    desired_weight = 30\n",
    "    desired_radius = 550\n",
    "    secondpass_cutoff_weight = 50\n",
    "    weight_importance_factor = 1\n",
    "\n",
    "else:\n",
    "\n",
    "    gdf_for_cluster = gpd.read_parquet(INPUT_DATA_DIR / \"grids.parquet\")\n",
    "    # admin variables\n",
    "    id_col = \"grid_id\"\n",
    "    lat_col = \"Lat\"\n",
    "    lon_col = \"Lon\"\n",
    "    weight_col = \"population\"\n",
    "    epsg = 3121  # philippines\n",
    "    # clustering variables\n",
    "    desired_weight = 240\n",
    "    desired_radius = 1000\n",
    "    weight_importance_factor = 1\n",
    "    secondpass_cutoff_weight = 300\n",
    "\n",
    "gdf_for_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_doublepass_gdf = get_optimised_kmeans_clusters_doublepass(\n",
    "    gdf=gdf_for_cluster,\n",
    "    lat_col=lat_col,\n",
    "    lon_col=lon_col,\n",
    "    weight_col=weight_col,\n",
    "    epsg=epsg,\n",
    "    desired_cluster_weight=desired_weight,\n",
    "    max_cluster_weight = 40,\n",
    "    desired_cluster_radius=desired_radius,\n",
    "    weight_importance_factor=weight_importance_factor,\n",
    "    doubplepass=True,\n",
    "    initial_n_trials=firstpass_n_trials,\n",
    "    secondpass_n_trials=secondpass_n_trials,\n",
    "    show_progress_bar=True,\n",
    "    return_type=\"gdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights_vs_radii(point_gdf_w_cluster=clusters_doublepass_gdf, point_weight_col=weight_col, point_projected_epsg=epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_doublepass_gdf[\"cluster_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[clusters_doublepass for clusters_doublepass in clusters_doublepass_gdf[\"cluster_id\"] if len(clusters_doublepass.split(\"_\")) == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "- add option for dynamic radius selection back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_data(gdf_for_cluster):\n",
    "\n",
    "    if gdf_for_cluster[weight_col].sum() == 0:\n",
    "        gdf_w_clusters = gdf_for_cluster.copy()\n",
    "        gdf_w_clusters.loc[:, \"cluster_id\"] = \"CLUSTER_0\"\n",
    "        gdf_w_clusters.loc[:, \"cluster_weight\"] = 0.0\n",
    "        gdf_w_clusters.loc[:, \"dense_area_guess\"] = 0\n",
    "        return gdf_w_clusters\n",
    "\n",
    "    # first pass\n",
    "    study_firstpass = run_optuna_kmeans_study(\n",
    "        gdf=gdf_for_cluster,\n",
    "        desired_cluster_weight=desired_weight,\n",
    "        desired_cluster_radius=desired_radius,\n",
    "        id_col=id_col,\n",
    "        lat_col=lat_col,\n",
    "        lon_col=lon_col,\n",
    "        weight_col=weight_col,\n",
    "        weight_importance_factor=desired_weight,\n",
    "        epsg=epsg,\n",
    "        n_trials=firstpass_n_trials,\n",
    "        n_jobs=n_jobs,\n",
    "        show_progress_bar=True,\n",
    "    )\n",
    "\n",
    "    # proper run with the best n_cluster\n",
    "    clusters = custom_kmeans(\n",
    "        df=gdf_for_cluster,\n",
    "        n_clusters=study_firstpass.best_params[\"n_clusters\"],\n",
    "        id_col=id_col,\n",
    "        lat_col=lat_col,\n",
    "        lon_col=lon_col,\n",
    "        weight_col=weight_col,\n",
    "    )\n",
    "    gdf_w_clusters = gdf_for_cluster.merge(clusters, on=id_col)\n",
    "    gdf_w_clusters = gdf_w_clusters.sort_values(by=\"cluster_id\")\n",
    "\n",
    "    # second pass\n",
    "    oversized_cluster_ids = get_oversized_clusters(\n",
    "        gdf_w_clusters=gdf_w_clusters, cutoff_weight=secondpass_cutoff_weight\n",
    "    )\n",
    "    n_oversized = len(oversized_cluster_ids)\n",
    "    print(f\"Oversized clusters: {n_oversized}\")\n",
    "\n",
    "    # add urban_guess column\n",
    "    gdf_w_clusters.loc[:, \"dense_area_guess\"] = 0\n",
    "    gdf_w_clusters.loc[\n",
    "        gdf_w_clusters[\"cluster_weight\"] > secondpass_cutoff_weight,\n",
    "        \"dense_area_guess\",\n",
    "    ] = 1\n",
    "\n",
    "    # second pass\n",
    "    # if n_oversized > 0:\n",
    "    #     # run re-clustering\n",
    "    #     gdf_w_clusters = kmeans_secondpass(\n",
    "    #         gdf_w_clusters=gdf_w_clusters,\n",
    "    #         oversized_cluster_ids=oversized_cluster_ids,\n",
    "    #         desired_cluster_weight=desired_weight,\n",
    "    #         desired_cluster_radius=desired_radius,\n",
    "    #         id_col=id_col,\n",
    "    #         lat_col=lat_col,\n",
    "    #         lon_col=lon_col,\n",
    "    #         weight_col=weight_col,\n",
    "    #         weight_importance_factor=weight_importance_factor,\n",
    "    #         epsg=epsg,\n",
    "    #         n_trials=secondpass_n_trials,\n",
    "    #         n_jobs=n_jobs,\n",
    "    #     )\n",
    "    #     gdf_w_clusters = gdf_w_clusters.sort_values(by=\"cluster_id\")\n",
    "\n",
    "    return gdf_w_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_w_clusters = cluster_data(gdf_for_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single pass timings\n",
    "\n",
    "# grids - 69,226 points different weights (smaller n_clusters)\n",
    "# original: 17s\n",
    "# new: 28s.....\n",
    "\n",
    "# rooftops - 17,367 points equal weight (much bigger n_clusters)\n",
    "# original: 33s\n",
    "# new: 35s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights_vs_radii(point_gdf_w_cluster=gdf_w_clusters, point_weight_col=weight_col, point_projected_epsg=epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_w_clusters.plot(column=\"cluster_id\", figsize=(5, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gridsample",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
